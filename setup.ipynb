{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e59cc-f80b-4846-b36c-edce2d5e5c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52da60-24d3-46e6-ae85-a59fb3de99c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d5a93-90c6-4dea-b640-e2e6029c5f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8efc957d-cbae-4aa6-b81a-9cddc9c77933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 30 18:18:30 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   45C    P0    60W / 150W |   4987MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     68329      C   /usr/bin/python3                 4985MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b80b9c-ba42-44d9-8856-247b3cb8ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup 1 (just run this once)\n",
    "import os\n",
    "import glob\n",
    "!git clone https://github.com/effusiveperiscope/so-vits-svc -b eff-4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170106a-ff0f-497c-a6ac-4b20bde16b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('so-vits-svc')\n",
    "# install requirements one-at-a-time to ignore exceptions\n",
    "!cat requirements.txt | xargs -n 1 pip install --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install praat-parselmouth\n",
    "!pip install ipywidgets\n",
    "!pip install huggingface_hub\n",
    "!pip install pip==23.0.1 # fix pip version for fairseq install\n",
    "!pip install fairseq==0.12.2\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "!pip install numpy==1.21\n",
    "!pip install --upgrade protobuf=3.9.2\n",
    "!pip uninstall -y tensorflow\n",
    "!pip install tensorflow==2.11.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7027f1e-bdff-421d-b64b-534075b06b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown \n",
    "existing_files = glob.glob('/home/ubuntu/**/*.*', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551cc5f-35c0-4117-ace6-6cc3f83b3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "# taken from https://github.com/CookiePPP/cookietts/blob/master/CookieTTS/utils/dataset/extract_unknown.py\n",
    "def extract(path):\n",
    "    if path.endswith(\".zip\"):\n",
    "        with ZipFile(path, 'r') as zipObj:\n",
    "           zipObj.extractall(os.path.split(path)[0])\n",
    "    elif path.endswith(\".tar.bz2\"):\n",
    "        tar = tarfile.open(path, \"r:bz2\")\n",
    "        tar.extractall(os.path.split(path)[0])\n",
    "        tar.close()\n",
    "    elif path.endswith(\".tar.gz\"):\n",
    "        tar = tarfile.open(path, \"r:gz\")\n",
    "        tar.extractall(os.path.split(path)[0])\n",
    "        tar.close()\n",
    "    elif path.endswith(\".tar\"):\n",
    "        tar = tarfile.open(path, \"r:\")\n",
    "        tar.extractall(os.path.split(path)[0])\n",
    "        tar.close()\n",
    "    elif path.endswith(\".7z\"):\n",
    "        import py7zr\n",
    "        archive = py7zr.SevenZipFile(path, mode='r')\n",
    "        archive.extractall(path=os.path.split(path)[0])\n",
    "        archive.close()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{path} extension not implemented.\")\n",
    "\n",
    "# taken from https://github.com/CookiePPP/cookietts/tree/master/CookieTTS/_0_download/scripts\n",
    "\n",
    "# megatools download urls\n",
    "win64_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-win64.zip\"\n",
    "win32_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-win32.zip\"\n",
    "linux_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-linux-x86_64.tar.gz\"\n",
    "# download megatools\n",
    "from sys import platform\n",
    "import os\n",
    "import urllib.request\n",
    "import subprocess\n",
    "from time import sleep\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "        dl_url = linux_url\n",
    "elif platform == \"darwin\":\n",
    "    raise NotImplementedError('MacOS not supported.')\n",
    "elif platform == \"win32\":\n",
    "        dl_url = win64_url\n",
    "else:\n",
    "    raise NotImplementedError ('Unknown Operating System.')\n",
    "\n",
    "dlname = dl_url.split(\"/\")[-1]\n",
    "if dlname.endswith(\".zip\"):\n",
    "    binary_folder = dlname[:-4] # remove .zip\n",
    "elif dlname.endswith(\".tar.gz\"):\n",
    "    binary_folder = dlname[:-7] # remove .tar.gz\n",
    "else:\n",
    "    raise NameError('downloaded megatools has unknown archive file extension!')\n",
    "\n",
    "if not os.path.exists(binary_folder):\n",
    "    print('\"megatools\" not found. Downloading...')\n",
    "    if not os.path.exists(dlname):\n",
    "        urllib.request.urlretrieve(dl_url, dlname)\n",
    "    assert os.path.exists(dlname), 'failed to download.'\n",
    "    extract(dlname)\n",
    "    sleep(0.10)\n",
    "    os.unlink(dlname)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "binary_folder = os.path.abspath(binary_folder)\n",
    "\n",
    "def megadown(download_link, filename='.', verbose=False):\n",
    "    \"\"\"Use megatools binary executable to download files and folders from MEGA.nz .\"\"\"\n",
    "    filename = ' --path \"'+os.path.abspath(filename)+'\"' if filename else \"\"\n",
    "    wd_old = os.getcwd()\n",
    "    os.chdir(binary_folder)\n",
    "    try:\n",
    "        if platform == \"linux\" or platform == \"linux2\":\n",
    "            subprocess.call(f'./megatools dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}', shell=True)\n",
    "        elif platform == \"win32\":\n",
    "            subprocess.call(f'megatools.exe dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}', shell=True)\n",
    "    except:\n",
    "        os.chdir(wd_old) # don't let user stop download without going back to correct directory first\n",
    "        raise\n",
    "    os.chdir(wd_old)\n",
    "    return filename\n",
    "\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import gdown\n",
    "from os.path import exists\n",
    "\n",
    "def request_url_with_progress_bar(url, filename):\n",
    "    class DownloadProgressBar(tqdm):\n",
    "        def update_to(self, b=1, bsize=1, tsize=None):\n",
    "            if tsize is not None:\n",
    "                self.total = tsize\n",
    "            self.update(b * bsize - self.n)\n",
    "    \n",
    "    def download_url(url, filename):\n",
    "        with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                                 miniters=1, desc=url.split('/')[-1]) as t:\n",
    "            filename, headers = urllib.request.urlretrieve(url, filename=filename, reporthook=t.update_to)\n",
    "            print(\"Downloaded to \"+filename)\n",
    "    download_url(url, filename)\n",
    "\n",
    "\n",
    "def download(urls, dataset='', filenames=None, force_dl=False, username='', password='', auth_needed=False):\n",
    "    assert filenames is None or len(urls) == len(filenames), f\"number of urls does not match filenames. Expected {len(filenames)} urls, containing the files listed below.\\n{filenames}\"\n",
    "    assert not auth_needed or (len(username) and len(password)), f\"username and password needed for {dataset} Dataset\"\n",
    "    if filenames is None:\n",
    "        filenames = [None,]*len(urls)\n",
    "    for i, (url, filename) in enumerate(zip(urls, filenames)):\n",
    "        print(f\"Downloading File from {url}\")\n",
    "        #if filename is None:\n",
    "        #    filename = url.split(\"/\")[-1]\n",
    "        if filename and (not force_dl) and exists(filename):\n",
    "            print(f\"{filename} Already Exists, Skipping.\")\n",
    "            continue\n",
    "        if 'drive.google.com' in url:\n",
    "            assert 'https://drive.google.com/uc?id=' in url, 'Google Drive links should follow the format \"https://drive.google.com/uc?id=1eQAnaoDBGQZldPVk-nzgYzRbcPSmnpv6\".\\nWhere id=XXXXXXXXXXXXXXXXX is the Google Drive Share ID.'\n",
    "            gdown.download(url, filename, quiet=False)\n",
    "        elif 'mega.nz' in url:\n",
    "            megadown(url, filename)\n",
    "        else:\n",
    "            #urllib.request.urlretrieve(url, filename=filename) # no progress bar\n",
    "            request_url_with_progress_bar(url, filename) # with progress bar\n",
    "\n",
    "import huggingface_hub\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "class HFModels:\n",
    "    def __init__(self, repo = \"therealvul/so-vits-svc-4.0\", \n",
    "            model_dir = \"hf_vul_models\"):\n",
    "        self.model_repo = huggingface_hub.Repository(local_dir=model_dir,\n",
    "            clone_from=repo, skip_lfs_files=True)\n",
    "        self.repo = repo\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        self.model_folders = os.listdir(model_dir)\n",
    "        self.model_folders.remove('.git')\n",
    "        self.model_folders.remove('.gitattributes')\n",
    "\n",
    "    def list_models(self):\n",
    "        return self.model_folders\n",
    "\n",
    "    # Downloads model;\n",
    "    # copies config to target_dir and moves model to target_dir\n",
    "    def download_model(self, model_name, target_dir):\n",
    "        if not model_name in self.model_folders:\n",
    "            raise Exception(model_name + \" not found\")\n",
    "        model_dir = self.model_dir\n",
    "        charpath = os.path.join(model_dir,model_name)\n",
    "\n",
    "        gen_pt = next(x for x in os.listdir(charpath) if x.startswith(\"G_\"))\n",
    "        cfg = next(x for x in os.listdir(charpath) if x.endswith(\"json\"))\n",
    "        try:\n",
    "          clust = next(x for x in os.listdir(charpath) if x.endswith(\"pt\"))\n",
    "        except StopIteration as e:\n",
    "          print(\"Note - no cluster model for \"+model_name)\n",
    "          clust = None\n",
    "\n",
    "        if not os.path.exists(target_dir):\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "        gen_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
    "            filename = model_name + \"/\" + gen_pt) # this is a symlink\n",
    "        \n",
    "        if clust is not None:\n",
    "          clust_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
    "              filename = model_name + \"/\" + clust) # this is a symlink\n",
    "          shutil.move(os.path.realpath(clust_dir), os.path.join(target_dir, clust))\n",
    "          clust_out = os.path.join(target_dir, clust)\n",
    "        else:\n",
    "          clust_out = None\n",
    "\n",
    "        shutil.copy(os.path.join(charpath,cfg),os.path.join(target_dir, cfg))\n",
    "        shutil.move(os.path.realpath(gen_dir), os.path.join(target_dir, gen_pt))\n",
    "\n",
    "        return {\"config_path\": os.path.join(target_dir,cfg),\n",
    "            \"generator_path\": os.path.join(target_dir,gen_pt),\n",
    "            \"cluster_path\": clust_out}\n",
    "\n",
    "# Example usage\n",
    "# vul_models = HFModels()\n",
    "# print(vul_models.list_models())\n",
    "# print(\"Applejack (singing)\" in vul_models.list_models())\n",
    "# vul_models.download_model(\"Applejack (singing)\",\"models/Applejack (singing)\")\n",
    "\n",
    "    print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcb3f0-2156-46bb-94b4-23d9a31767d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "download([\"https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/checkpoint_best_legacy_500.pt\"], filenames=[\"hubert/checkpoint_best_legacy_500.pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d888b-6593-4515-89be-0b1be7ed6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Other Downloads (.zip) Step o.1\n",
    "#@markdown Please note that 3.0 models are incompatible with 4.0.\n",
    "\n",
    "#@markdown Supported URL types: \n",
    "#@markdown * Google Drive zip\n",
    "#@markdown * MEGA zip\n",
    "#@markdown * Direct zip (+HuggingFace /resolve/ link)\n",
    "\n",
    "#@markdown Example URLs:\n",
    "#@markdown * Kanye: https://mega.nz/file/P7hWwCoQ#s0OICnRbTpcUjUIS7iQPIlYwBVelZXzm_-1LLPSUd2Y\n",
    "#@markdown * Kendrick: https://mega.nz/file/WmBzgSZa#UD-SFhHBv3aw0obTHW2lGc5yeaMnK8qtKU3OjDKMVKk\n",
    "#@markdown * Carti (v3): https://mega.nz/file/jnwzEJ4K#erlpUaNQ3VyQIIVaQDYge3Kv4pZtyNfQBWA6hUy6uu8\n",
    "#@markdown * AI Hub: https://discord.gg/Aktyxz4jwA\n",
    "\n",
    "\n",
    "import re\n",
    "model_url = \"https://mega.nz/file/WmBzgSZa#UD-SFhHBv3aw0obTHW2lGc5yeaMnK8qtKU3OjDKMVKk\" #@param {\"type\": \"string\"}\n",
    "if \"huggingface.co\" in model_url.lower():\n",
    "  download([re.sub(r\"/blob/\",\"/resolve/\",model_url)], \n",
    "           filenames=[os.path.join(os.getcwd(),model_url.split(\"/\")[-1])])\n",
    "else:\n",
    "  download([model_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38b2a6-3f2e-4f81-8845-34f7164b315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Extract .zip Downloads - Step o.2\n",
    "# download speaker model files into 'models' directory\n",
    "import glob, os, shutil\n",
    "from pathlib import Path\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model_zip_paths = glob.glob('/home/ubuntu/**/*.zip', recursive=True)\n",
    "for model_zip_path in model_zip_paths:\n",
    "    extract(model_zip_path) # extract inplace\n",
    "    ckpts_inplace = glob.glob('./*.pth')\n",
    "    json_inplace = glob.glob('./*.json')\n",
    "    if os.path.exists(os.path.splitext(model_zip_path)[0]):\n",
    "      shutil.move(os.path.splitext(model_zip_path)[0],'models')\n",
    "    elif len(ckpts_inplace):\n",
    "      for f in ckpts_inplace:\n",
    "        os.makedirs('models/'+Path(model_zip_path).stem, \n",
    "                      exist_ok=True)\n",
    "        shutil.move(f,'models/'+Path(model_zip_path).stem)\n",
    "      for f in json_inplace:\n",
    "        shutil.move(f,'models/'+Path(model_zip_path).stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4206eed-7490-4e16-9a97-f235078612ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
